#Параллелизм 
[[Подход Map-reduce]]
# Hadoop
## Пример задачи

![[Pasted image 20231219191145.png]]

Пусть некий табличный лог пишется в **hadoop кластер**. **Hadoop** сам разложит эту "таблицу" на разные серверы (обычно называется "**ноды**" **node**). 

Мы хотим узнать сколько всего денег покупатели потратили на каждый тип фруктов?

За распределение данных по кластеру отвечает _HDFS (Hadoop Distributed File System_). Из-за того, что данные разделены на разные ноды, объем данных не ограничен размером жесткого диска одной ноды. А репликация обеспечивает отказоустойчивость (если одна из нод сломается, реплика встанет на ее место).

![[Pasted image 20231219191311.png]]

## Map

Для каждой записи вызовется функция map, сформировав промежуточные пары "ключ-значение"

![[Pasted image 20231219191540.png]]

## Shuffle

Этот шаг произведет сам hadoop. Мы только должны сказать ему, какой столбец будет ключом. В нашем случае ключом будет столбец _fruit_. Ноды будут обмениваться строчками так, чтобы   все строчки с одинаковым ключом попали на одну ноду.

![[Pasted image 20231219191642.png]]

## Reduce

Функция **reduce**, совсем не отличается от функции **reduce** в ФП