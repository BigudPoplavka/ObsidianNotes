#Итерационные_методы #Машинное_обучение #Функция 

[[Градиент]]
[[Метод наискорейшего градиентного спуска]]

![[Pasted image 20220604173007.png]]

<b> Уменьшение функции потерь - это и есть обучение нейросети </b>
[[Расчёт функции потерь]]

![[Pasted image 20220604173127.png]]

То есть мы считаем градиент не для всего датасета за раз, а для его отдельных выборок, выбирающихся случайным образом - **==отсюда название стахостический==**