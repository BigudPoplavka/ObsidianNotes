 #Машинное_обучение #Нейросети #CV

[[Свертка]]
[[Нейрон]]
[[Обратное распространение ошибки]]
## Общие положения

**Сверточная** нейронная сеть основана на удивительно мощной и универсальной **математической операции**. В этой статье мы шаг за шагом рассмотрим механизм их работы на примере стандартной полностью рабочей сети, и изучим то, как они строят качественные визуальные иерархии.

![[Pasted image 20240725133103.png]]

*Сверточная НС имеет специальную архитектуру, которая позволяет ей максимально эффективно распознавать образы.* 
## Принцип работы

Сама идея СНС основывается **на чередовании сверточных и субдискретизирующих слоев (pooling)**, а структура является однонаправленной. **СНС получила свое название от операции свертки**, которая предполагает, **что каждый фрагмент изображения будет умножен на ==ядро свертки== поэлементно**, при этом полученный результат должен суммироваться и записаться в похожую позицию выходного изображения. Такая архитектура обеспечивает инвариантность распознавания относительно сдвига объекта, **постепенно укрупняя «окно», на которое «смотрит» свёртка, выявляя всё более и более крупные структуры и паттерны в изображении**.

> **Фильтр (ядро свертки)** — это небольшой **двумерный массив чисел** (например, 3x3 или 5x5), который используется для выделения определенных признаков на изображении, таких как края, текстуры и углы. **Значения фильтра (веса) инициализируются случайным образом и оптимизируются в процессе обучения сети.**

**Эта архитектура обрабатывает данные не целиком, а фрагментами**, но при этом данные не дробятся на части, а осуществляется своего рода последовательный прогон. Затем данные передаются дальше по слоям. Кроме **свёрточных слоёв** (С) используются также **слои объединения (P — pooling)**. Например, из аудиодорожки выбираются только ключевые моменты: пики амплитуд и паузы. Слои объединения сжимаются с глубиной (обычно степенью двойки). К конечным слоям добавляются несколько персептронов (сеть прямого распространения), для последующей обработке данных. 
### Двумерная сверточная нейронная сеть

**Двумерная свертка (2D convolution)** — это довольно простая операция:
1. начинаем **==с ядра, представляющего из себя матрицу весов (weight matrix)==**. Ядро “скользит” над двумерным изображением, **поэлементно выполняя операцию умножения с той частью входных данных, над которой оно сейчас находится**, 
2. и затем **суммирует все полученные значения в один выходной пиксель.**

Ядро повторяет эту процедуру с каждой локацией, над которой оно “скользит”, **преобразуя двумерную матрицу в другую все еще двумерную матрицу признаков**. 

> Признаки на выходе являются взвешенными суммами (где веса являются значениями самого ядра) признаков на входе, расположенных примерно в том же месте, что и выходной пиксель на входном слое.

Независимо от того, попадает ли входной признак в “примерно то же место”, он определяется в зависимости от того, находится он в зоне ядра, создающего выходные данные, или нет. Это значит, что ==**размер ядра сверточной нейронной сети определяет количество признаков, которые будут объединены для получения нового признака на выходе.**==

## Часто используемые техники

Перед тем как мы двинемся дальше, безусловно стоит взглянуть на две техники, которые часто применяются в сверточных нейронных сетях: Padding и Striding.

[[Padding]]
[[Striding]]
## Многоканальная версия сверточной нейронной сети

Приведенные выше диаграммы касаются только случая, когда изображение имеет один входной канал. На практике большинство входных изображений имеют 3 канала, и чем глубже вы в сети, тем больше это число.

![[Pasted image 20240725143437.png]]

==Вот где ключевые различия между терминами становятся нужными: тогда как в случае с 1 каналом термины «фильтр» и «ядро» взаимозаменяемы, в общем случае они разные.==

![сверточная нейронная сеть - работа](https://neurohive.io/wp-content/uploads/2018/07/kernels.png)

> **Каждый фильтр на самом деле представляет собой коллекцию ядер**, причем для каждого отдельного входного канала этого слоя есть одно ядро, и каждое ядро уникально.

==**Каждый фильтр в сверточном слое создает только один выходной канал**== и делают они это так: 
- **каждое из ядер фильтра** «скользит» по их соответствующим входным каналам, создавая обработанную версию каждого из них. 
- Некоторые ядра могут иметь больший вес, чем другие, для того чтобы уделять больше внимания определенным входным каналам (например, фильтр может задать красному каналу ядра больший вес, чем другим каналам, и, следовательно, больше реагировать на различия в образах из красного канала).

![[Pasted image 20240725143636.png]]

- Затем каждая из обработанных в канале версий суммируется вместе для формирования одного канала. Ядра каждого фильтра генерируют одну версию каждого канала, а фильтр в целом создает один общий выходной канал:

![[Pasted image 20240725143752.png]]

Наконец, каждый выходной файл имеет свое смещение. Смещение добавляется к выходному каналу для создания конечного выходного канала:

![[Pasted image 20240725144350.png]]

> Результат для любого количества фильтров идентичен: каждый фильтр обрабатывает вход со своим отличающимся от других набором ядер и скалярным смещением по описанному выше процессу, **создавая один выходной канал**. Затем они объединяются вместе для получения общего выхода, причем ==количество выходных каналов равно числу фильтров.== При этом обычно применяется нелинейность перед передачей входа другому слою свертки, который затем повторяет этот процесс.

## Локальные особенности

- Ядра объединяют пиксели только из небольшой локальной области для формирования выхода. То есть выходные признаки видят только входные признаки из небольшой локальной области;
- Ядро применяется глобально по всему изображению для создания матрицы выходных значений.
- Таким образом, с backpropagation, идущим во всех направлениях от узлов классификации сети, ядра имеют интересную задачу изучения весов для создания признаков только из локального набора входов. Кроме того, поскольку само ядро применяется по всему изображению, признаки, которые изучает ядро, должны быть достаточно общими, чтобы поступать из любой части изображения.
## Параметры в СНС


## Архитектуры

[[AlexNet]]
[[ResNet]]
[[NetVLAD]]