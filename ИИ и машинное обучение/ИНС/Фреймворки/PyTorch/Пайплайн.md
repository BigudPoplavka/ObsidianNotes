#Машинное_обучение #глубокое_обучение #Нейросети 

[[Регрессия]]
[[Pooling]]
### Шаги создания нейросети на PyTorch

## 1. Установка и подключение библиотек
    
Для любой задачи вам понадобятся стандартные импорты:

`import torch`
`import torch.nn as nn`
`import torch.optim as optim`
`from torch.utils.data import DataLoader`
`from torchvision import datasets, transforms`

- - `torch` и `torch.nn` — для работы с тензорами и создания нейросети.
- `torch.optim` — для выбора оптимизатора.
- `torch.utils.data.DataLoader` — для загрузки данных.
- `torchvision` — для удобной работы с изображениями и предобработки.
## 2. Определение архитектуры нейросети
    
- **Классификация изображений** — Пример простой CNN (Convolutional Neural Network).
- **Детекция с bounding boxes** — Архитектуры типа YOLO или Faster R-CNN, использующие якоря для детекции объектов.
- **Распознавание bounding boxes по тексту** — Использование архитектур, комбинирующих CNN для изображений и RNN/Transformer для текста.
## Решение задач

### Классификация

#### Архитектура:

Используются сверточные слои (Conv) для выделения признаков, пулинговые слои (Pool) для уменьшения размерности и fully connected (FC) слои для классификации.
![[Pasted image 20241010002547.png]]
#### Слои:
- **Conv2d** — извлечение признаков из изображений.
- **MaxPool2d** — уменьшение размерности, сохраняя важные признаки.
- **Linear** — полносвязные слои для классификации.
#### Алгоритм:

1. Понять размер входного изображения (например, 32x32 для CIFAR).
2. Выстроить слои, начиная с **Conv** и заканчивая **FC**, уменьшая размерность через **пулинг**.
3. Использовать **CrossEntropyLoss** для классификации.
### Детекция объектов с Bounding Boxes

Для задачи детекции используются более сложные модели, такие как **YOLO** или **Faster R-CNN**. Эти архитектуры требуют предсказания как классов, так и координат bounding boxes.

![[Pasted image 20241010002605.png]]
#### Алгоритм:

1. Входное изображение обрабатывается сверточными слоями для извлечения признаков.
2. Параллельные ветви нейросети предсказывают координаты боксов и классы объектов.
3. Использовать функцию потерь, комбинирующую регрессию для bbox и классификацию для классов (`MSELoss` для bbox, `CrossEntropyLoss` для классов).
### Распознавание bounding boxes по тексту

В этой задаче комбинация CNN для обработки изображения и RNN или Transformer для работы с текстом. Модель принимает изображение и описание, а затем предсказывает bounding boxes.

Пример упрощённой архитектуры:

![[Pasted image 20241010003548.png]]

- **GRU** — используется для обработки текстового ввода.
- **fc_bbox** — слой предсказывает координаты боксов на основе объединённых признаков изображения и текста.
#### Алгоритм:

1. CNN обрабатывает изображение для извлечения признаков.
2. Текстовое описание преобразуется в вектор с помощью Embedding и RNN/Transformer.
3. Признаки изображения и текста объединяются и используются для предсказания координат боксов.
### Почему используется кросс-энтропия?

В первой задаче (классификация изображений) целью является предсказание класса для каждого изображения. Мы используем **кросс-энтропию** (`CrossEntropyLoss`) как функцию потерь, потому что она является стандартной для задач многоклассовой классификации.

Кросс-энтропия измеряет разницу между распределением вероятностей, предсказанным моделью, и реальным распределением (one-hot кодирование класса). Эта функция потерь хорошо подходит для случаев, когда:

- Имеется конечное количество классов (например, 10 классов для CIFAR-10).
- Предсказываются вероятности классов (softmax на выходе последнего слоя).
- Задача заключается в том, чтобы минимизировать различие между этими предсказанными вероятностями и истинными метками.
### x-view

Функция `.view()` изменяет (перестраивает) размерность тензора, не изменяя его данные. Она полезна, когда нужно перейти от многомерного тензора (например, после свёрточных слоёв) к одномерному тензору для его дальнейшей обработки в полносвязных слоях (fully connected layers).

**Пример**: После свёрточных слоёв выходной тензор обычно имеет форму batch size×channels×height×width. **Полносвязные** слои принимают на вход **==одномерные==** тензоры, поэтому необходимо преобразовать (**flatten**) многомерные данные.

**`-1`**: Это специальный параметр, который позволяет PyTorch автоматически вычислить это измерение на основе общего количества элементов в тензоре. Он используется, когда ты точно знаешь все остальные размеры, но не хочешь вручную вычислять размер для первой оси (например, размера батча). PyTorch вычислит это значение автоматически, исходя из общего числа элементов в тензоре.

Пример: Если входное изображение имеет форму` batch size×64×8×8`, то PyTorch автоматически определит, что батч должен оставаться неизменным, а вот оставшиеся размеры мы задаём сами.
### Почему выбраны именно такие значения?

- **64**: Количество выходных каналов задаётся вторым свёрточным слоем `nn.Conv2d(32, 64, ...)`, где 64 — это количество фильтров (или ядер свёртки) в этом слое. Это означает, что на выходе мы получаем 64 разных набора признаков для каждого фрагмента изображения.
- **8 * 8**: **==Этот размер получен после нескольких операций свёртки и пулинга,==** которые уменьшают пространственные размеры входных данных. Например, если начальное изображение было размером **==32×32==**, то **==после двух== свёрток с пулингом (каждый уменьшает размер ==в 2 раза==) остаётся ==8×8==** 

## FC-слои для классификации

### 1. Промежуточный слой для обработки признаков:

Первый полносвязный слой (`fc1`) выполняет роль преобразования и обобщения полученных признаков от свёрточных слоёв:

- После свёрточных слоёв и операций пулинга выходной тензор имеет размер batch size×64×8×8\text{batch size} \times 64 \times 8 \times 8batch size×64×8×8. Это соответствует 4096 признакам (64 канала по размеру 8x8), которые необходимо передать в полносвязный слой для дальнейшей обработки.
- Линейный слой `fc1` уменьшает эту высокоразмерную информацию (4096 признаков) до более компактного набора признаков — 128. Это своего рода **сжатие и обобщение признаков**. Задача этого слоя — выявить наиболее важные признаки из исходного многомерного признакового пространства.
### 2. Добавление нелинейности и активации:

- После первого полносвязного слоя часто используется функция активации (например, ReLU), чтобы ввести нелинейность в модель. Нелинейности позволяют нейросети лучше представлять сложные зависимости и взаимоотношения между признаками.
- Нелинейность нужна для того, чтобы модель могла эффективно обучаться на сложных данных, иначе сеть с последовательными линейными слоями просто обучала бы линейные зависимости, что ограничивает её выразительность.
### 3. Финальный слой для предсказания классов:

Второй полносвязный слой (`fc2`) служит для преобразования выходов промежуточного слоя (128 признаков) в окончательное предсказание классов:

- Этот слой преобразует 128 признаков в количество классов, которое мы задаём переменной `num_classes`. Например, если у нас задача классификации с 10 классами (например, CIFAR-10), то `num_classes` будет равен 10.
- Финальный выход этого слоя передаётся через функцию активации, такую как **softmax** (или в случае PyTorch — через функцию потерь, например, **CrossEntropyLoss**, которая включает в себя softmax):

 