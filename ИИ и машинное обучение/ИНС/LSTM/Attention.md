#LSTM #Обработка_последовательностей

**Механизм внимания** (англ. _attention mechanism_, _attention model_) — техника используемая в рекуррентных нейронных сетях (сокр. _RNN_) и сверточных нейронных сетях(сокр. _CNN_) для поиска взаимосвязей между различными частями входных и выходных данных.

**Attention** - механизм, реализующий способность сети обращать внимание на определенную часть данных, наиболее контекстно важную.

Ключевые отправные точки:
- работа с текстами и машинный перевод
- работа с последовательностями
- **parallel corpora / rosetta stone** - один и тот же текст на разных языках
## Задача attention

> Задача attention - вектор с информацией о предложении в конце энкодера должен  передать всю информацию (в один вектор) на декодер. Для больших предложений это может влиять на работу модели. 
> 
> Когда модель на конкретной ячейке смотрит на текущую информацию о слове, хотелось бы иметь возможность заглянуть на информацию на шаг раньше.  
## LSTM

Энкодер и декодер в **LSTM (Long Short-Term Memory)** - это важные компоненты архитектуры нейронных сетей, используемые для задач последовательного обучения, таких как машинный перевод, автоматическое описание изображений и т.д. 

![[Pasted image 20240806135802.png]]

С этим связаны понятия декодера и энкодера.
Энкодер - принимающая часть
### Энкодер

**Энкодер** - ==**это часть модели, которая принимает входную последовательность и преобразует её в контекстное представление, называемое скрытым состоянием (hidden state).**== В LSTM энкодере каждый элемент входной последовательности обрабатывается последовательно, обновляя скрытое состояние на каждом шагу. Финальное скрытое состояние после обработки всей последовательности служит "сжатыми" данными, представляющими всю входную последовательность.
#### Основные шаги:

1. Входная последовательность: 
![[Pasted image 20240806132733.png]]

2. **LSTM ячейки:** На каждом шагу t входной элемент `x_t` обрабатывается LSTM ячейкой, обновляя скрытое состояние `h_t` и состояние ячейки `c_t`
3. **Скрытое состояние:** Финальное скрытое состояние `h_T` передаётся декодеру как контекстное представление в виде вектора.
### Декодер

Декодер принимает контекстное **представление от энкодера** и **генерирует выходную последовательность**. В задачах, таких как машинный перевод, декодер использует скрытое состояние от энкодера и предыдущие сгенерированные элементы для предсказания следующего элемента последовательности.
#### Основные шаги:

1. **Инициализация:** Декодер инициализируется скрытым состоянием (представлением) `h_T`​ от энкодера.
2. **Генерация:** На каждом шагу `t`, используя скрытое состояние `h_t​` и состояние ячейки `c_t`, декодер генерирует элемент выходной последовательности `y_t`​.
3. **Петля:** Процесс повторяется до генерации всей выходной последовательности или до достижения условия остановки.
## Bidiretional LSTM

![[Pasted image 20240806140056.png]]

Является способом передачи последовательности в прямом и обратном порядке. Каждая ячейка здесь представляет собой `h = [f, b]`, forward и backword представление с каждого этапа.

Этим же образом создается контекст.

В данном случае **энкодер:**
![[Pasted image 20240806140344.png]]

**==В энкодере==** **(в зависимости от текущего state)** некст шаг получит некую **усредненную сумму из hidden-states энкодера** в зависимости от корреляции с предыдущим состоянием **==дэкодера==**. Благодаря этому мы понимаем какой из hidden states более близко подходит. 
![[Pasted image 20240806142228.png]]

Для этого:
1. **==специальный FC-layer принимает на входы State и hidden state==** и на выход дает число. При обработке таким образом всех `h_T` получаем набор `[a1 .. an]`
2. Их затем прогоняем через **softmax** для усреднения и нормализации. Каждое `a_T` соответствует своему `x_T`. 
3. Суммируем произведения `a_T` на `h_T` и **==эта сумма==** передается на следующий блок `Y_t `энкодера  
4. Таким образом **==декодер для каждого своего шага отдельно определяет какую контекстную информацию из прошлых шагов с энкодера==** ему нужно получить сейчас или же какая `h [h_forw, h_back]` наиболее важна

От чистого LSTM отличается тем, что к `Ct-1` и `Ht-1` добавляется еще контекстный вектор, формируемый  из  упомянутых произведений -
							||
![[Pasted image 20240806142445.png]]

#### Визуализация attention
![[Pasted image 20240806145012.png]]

## Функция Attention

> Функция attention - **==принять hidden state энкодера и декодера==** выдать число об их контекстной релевантности и совместимости.  

### Варианты:

- Сумма произведений выходов FC-слоя для релевантности на веса
- Векторное произведение векторов энкодера и дэкодера
- Вектор с энкодера на линейную трансформацию вектора с дэкодера
## Пример

В задаче машинного перевода:

- **Энкодер:** Обрабатывает входную фразу на исходном языке (например, английский) и создает контекстное представление.
- **Декодер:** Генерирует перевод на целевой язык (например, французский) на основе контекстного представления и предыдущих сгенерированных слов.

## Устройство Google-Translate

![[Pasted image 20240806145115.png]]

attention-вектор выдается от первого слоя декодера.
На attention идет **последний уровень энокодера** и **результат первого уровня дэкодера.** Это все идет на fully-cnnected layer, а его результат на всем слоям. 

Это помогает уведомить всю сеть о произошедшем attention для какой-то позиции `y_i`

## Перевод картинки в текст

### Image caption

Картинка дается на вход некой CNN - которая является энкодером. 
Для каждого вектора признаков LSTM предсказывает **attention-map** - то есть с какими весами взвесить значения пикселей в **соотв. фич-мапе**. Результат - взвешенная сумма - которая передается на след. слой LSTM. 

LSTM на каждом уровне выбирает на какую часть пространственной информации (feature-map) посмотреть для получения след. слова.

### Определение изображенного на картинке
### (Visual Question Answering)

![[Pasted image 20240807113325.png]]

- Есть **query** - текстовое описание картинки
- Есть CNN для экстракта признаков

![[Pasted image 20240807114124.png]]

1. ResNet CNN дает **вектор признаков** 
2. Из  **LSTM** делают энкодер про информацию в вопросе к картинке - получаем вектор и **тайлим** - **==преобразуем его в такой же по размеру map, как feature-map от CNN==**. В каждой ячейке map будет информация по query
3. **==Совмещают map-ы CNN и LSTM==** получая вектор признаков, где в одной ячейке хранится и информация query и соотв. значение пиксели из вектора CNN
4. Conv сеть далее получает на вход вектора query и CNN-feature-map и прогоняет через attention, получая **2  attention-map** соответственно для инфы из запроса и картинки
5. **Weighted average** - складываем вектор CNN с весами из полученных attention
6. На основании полученного вектора с усредненным attention на инфу из CNN последние FC-слои решают что выдать навыходе. 
## Преимущества использования LSTM

LSTM обладают способностью сохранять долгосрочные зависимости благодаря их специальной архитектуре, включающей ворота забывания, входные ворота и выходные ворота. Это позволяет LSTM справляться с задачами, где важны как недавние, так и далекие во времени элементы последовательности.
## Заключение

Энкодер и декодер в LSTM моделях - это ключевые компоненты для обработки и генерации последовательностей данных. 
- Энкодер преобразует входные данные в контекстное представление, которое затем используется декодером для генерации выходной последовательности. 
- Эта архитектура эффективна в широком диапазоне приложений, таких как машинный перевод, обработка естественного языка и автоматическое описание изображений.
## Ресурсы

Для более детального изучения можете обратиться к следующим источникам:

- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) - оригинальная статья о Seq2Seq.
- Understanding LSTM Networks - статья с объяснением работы LSTM.