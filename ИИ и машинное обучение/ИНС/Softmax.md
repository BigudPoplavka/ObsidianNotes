#Машинное_обучение 

**Softmax** — это функция активации, которая принимает вектор действительных чисел и преобразует их в распределение вероятностей. То есть на выходе мы получаем вектор, сумма значений которого равна 1, и каждое значение можно интерпретировать как вероятность принадлежности к определённому классу. Softmax делает следующее:
	
Мягкая максимизация заключается в том, что при нормализации значений `y` (результат перемножения весов и входов) до значений от **0 до 1** самые большие значения будут быстро приближены к 1, а наименьшие к 0.  То есть сохраняем прямую зависимость - чем больше было значение в векторе `y` , тем больше число его соответствующей вероятности.
	
Это достигается за счет использования **экспоненты** в силу ее характера быстрого роста при небольшом увеличении данных.

![[Pasted image 20240809113959.png]]

`z_i` - линейная комбинация - результат

![[Pasted image 20240809114309.png]]

Экспонента подходит т.к. в `e^y_0` делить на сумму для всех классов всегда даст результат от  **0 - 1**
Если мы сделаем так для всех классов, то сумма всех вероятностей будет 1

---
Softmax полезен, когда необходимо сделать многоклассовую классификацию, так как он "нормализует" выходы модели и превращает их в вероятности.