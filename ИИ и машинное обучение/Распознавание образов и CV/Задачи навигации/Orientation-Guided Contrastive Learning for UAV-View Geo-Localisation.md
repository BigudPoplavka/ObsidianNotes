#Машинное_обучение #CV #БПЛА

[[University-1652]]
[[University-1652 A Multi-view Multi-source Benchmark for Drone-based Geo-localization]]
## Аннотация

Извлечение релевантного мультимедийного контента является одной из основных
проблем в мире, который все больше управляется данными. С распространением беспилотников высококачественные кадры с воздуха
теперь впервые доступны широкой аудитории. Интеграция этих кадров в приложения может обеспечить геолокацию или коррекцию местоположения без GPS.
В этой статье мы представляем структуру обучения на основе ориентации для геолокации изображений с БПЛА. С помощью иерархической локализации ориентации изображений с БПЛА оцениваются по отношению к спутниковым снимкам. Мы предлагаем
легкий **==модуль прогнозирования для этих псевдометок,**
**который прогнозирует ориентацию между различными видами**
**на основе контрастных обученных вложений==**. Мы экспериментально демонстрируем, что это прогнозирование поддерживает обучение и превосходит предыдущие подходы. Извлеченные псевдометки также позволяют выровнять вращение спутникового
изображения **в качестве дополнения для дальнейшего усиления обобщения** (augumentation). Во время вывода нам больше не нужен этот модуль ориентации, что означает, что никаких дополнительных вычислений
не требуется. Мы достигаем самых современных результатов на наборах данных
University-1652 и University-160k.
## 1 Введение

Геолокации по изображениям могут помочь в различных ситуациях,
когда точный кинематический GPS в реальном времени (RTK) либо недоступен, либо слишком дорог, либо датчик GPS получает шумные
сигналы. Особенно в городах [[Эффект городского каньона]]
может создавать отклонения в несколько метров. 

**==Альтернативой спутниковой радионавигации является так называемая перекрестная локализация изображений, где для локализации используется взаимосвязь между**
**наземными и воздушными изображениями.==**

Текущие стандартные наборы данных, такие как [[CVUSA]], [[CVACT]] и
[[VIGOR]] , содержат **только спутниковые изображения** в сочетании
с **изображениями на уровне улиц** для определения положения уличного вида. С распространением беспилотных летательных аппаратов
(БПЛА), так называемых дронов, становится доступно все больше видео и изображений
с ​​точки зрения БПЛА. Локализация этих офлайн и онлайн может помочь в задачах навигации, доставки или масштабной 3D-реконструкции . Для разработки подходов, подходящих для изображений с БПЛА, Чжэн и др. представили исследовательскому
сообществу набор данных University-1652. В этом наборе данных изображения зданий, полученные с помощью дронов,
должны быть сопоставлены с соответствующими спутниковыми изображениями. Для
проверки дополнительного обобщения подходов выпущено расширение набора данных, а именно University-160k.
Это расширение содержит дополнительные спутниковые изображения
несвязанных регионов. Эти изображения служат в качестве шаблонов отвлечения
для повышения уровня сложности и проверки переносимости
в приложениях. Из-за большой спутниковой базы данных эффективность сопоставления между встраиваниями также должна быть принята во внимание для обеспечения готовых к производству приложений.
В современных подходах, основанных на глубоком обучении, встраивание обоих представлений изучается. Затем
выведенные вложения сопоставляются на основе **косинусного**
**сходства или расстояния ℓ2.** [[L-нормы]] [[Косинусное расстояние]]
  
  Как показали предыдущие наборы данных и подходы, выравнивание между географическим направлением
наземных и воздушных изображений обеспечивает решающее преимущество в
прогнозе. **==Но в наборе данных University-160k нет информации об ориентации==**. **==Поэтому мы используем метод локализации 6-DoF, для оценки ориентаций**
**отдельных видов дронов. Затем эти ориентации можно**
**разделить на направления, которые будут предсказаны как метки, как показано**
**на рисунке 2==**. Таким образом, кодер изображений неявно узнает, с какого направления было получено изображение дрона, и
выравнивает выведенные вложения. Кроме того, мы сравниваем
между архитектурами на основе CNN и Transformer, чтобы изучить наилучший компромисс между эффективностью и результативностью, и предлагаем простую очистку меток при наличии неопределенных видов и окклюзий.
## 2 Related Work 

Набор данных University-1652 — это первый многовидовой многоисточниковый эталон для геолокации с использованием изображений с дронов. Тренировочная и тестовая выборки содержат 701 уникальное здание каждого из университетов с 54 снимками с дронов и одним спутниковым снимком на здание. Для проверки обобщения было обеспечено отсутствие перекрытия между университетами в тренировочной и тестовой выборках. Чжэн и др. использовали **многоветвевую сверточную нейронную сеть для извлечения вложений видов и оптимизации их на основе потери экземпляра. Во время вывода слой классификации далее не используется**. Изображения с дронов в наборе данных представляют собой синтетические изображения, созданные с помощью Google Earth Studio. Они создаются автоматическим конвейером рендеринга, поэтому цвета отличаются от спутниковых изображений. Чтобы исправить это, Ху и др. предложили выравнивание стилей на основе статистики цвета и поворота изображений. **Поскольку здания находятся в центре внимания изображений, Лу и др. предложили контекстно-зависимый иерархический модуль выбора представления, который учится фокусироваться на областях карты признаков с высокой активацие**й. Однако Ван и др. утверждают, что вся информация, включая фоновую информацию, может быть важна, поскольку, например, дороги и деревья видны как на спутниковом снимке, так и на снимке с дрона. Поэтому они предложили объединение на основе кольцевого шаблона вместо обычного среднего объединения в конце сети. Для каждого изображения карта признаков делится на четыре меньших кольца, и каждое кольцо объединяется отдельно. Выходные векторы признаков затем используются по отдельности для расчета потерь.

**Из-за разных точек зрения выравнивание карт признаков может помочь найти сходства в изображениях, которые**
**должны быть сопоставлены. Минг и др. предложили lernable сегментацию признаков и выравнивание областей на основе выведенной**
**тепловой карты.** В их подходе псевдометки, соответствующие
тепловой карте, генерируются и используются для классификации переднего плана и
фона для дальнейшей поддержки выравнивания между различными видами.
**==Чтобы использовать дополнительную семантическую информацию о**
**высоте полета и угле наклона камеры, Чжу и др. кодируют текстовые**
**признаки с помощью модели BERT. В последующем модуле слияния**
**выходные данные Transformer объединяются с признаками изображения,**
**выведенными ResNetV2==**.
Поскольку задача геолокализации перекрестных видов может быть смоделирована
как классификация и извлечение для изучения соответствующих представлений, используются функции контрастных потерь. В частности, функции контрастных потерь выигрывают от жестких негативов,
и их выборка была изучена Деузером и др. В своей работе они предложили метод выборки на основе местоположения для использования жестких негативов с самого начала
обучения.
## 3 Методология

Как показала предыдущая работа, ориентация играет фундаментальную роль в обучении. Для ранее использованных
наборов данных географическая ориентация известна априори,
когда извлекаются 360-градусные изображения. Таким образом, например, вращение спутниковых изображений может использоваться как
метод дополнения данных, в котором ранее выровненное
360-градусное изображение затем поворачивается на величину вращения.
В наборе данных University-1652 эта ориентация неизвестна.
**==Однако при наличии нескольких изображений одного и того же объекта**
**ориентация и предполагаемое положение в пространстве могут быть определены из 3D-реконструкции с использованием методов Structure-fromMotion (SfM).==**
### 3.1 Иерархическая локализация

**На первом этапе нашего подхода необходимо оценить ориентацию**
**видов БПЛА.** Для этого мы используем готовый **==метод иерархической локализации (HLOC) Сарлина==** [[Метод иерархической локализации (HLOC) Сарлина]]
и др. Сначала генерируются глобальные дескрипторы с использованием
предварительно обученной CNN. Затем изображения упорядочиваются на грубом уровне с k-ближайшими соседями по глобальным дескрипторам.
Эти так называемые предшествующие кадры представляют собой кандидатов на местоположение
для сцены и затем кластеризуются в места на основе их
3D-структуры, которая генерируется с использованием [[SfM]]. Поскольку глобальные
признаки обычно слишком грубые, локальные признаки также извлекаются с помощью [[SuperPoint]]. Затем между изображениями в кластере сопоставляются локальные признаки, и поза с 6 степенями свободы
оценивается с помощью **PnP**. Из-за выбросов используется **RANSAC**
для повышения надежности оценки. Для прогнозирования ориентации мы используем спутниковое изображение в качестве привязки и назначаем каждому виду БПЛА псевдометку на основе угла
3D-координат.

![[Pasted image 20240822112422.png]]

Как показано на левой стороне рисунка 2, оценка
матриц преобразования реконструирует путь камеры,
который был сделан для фотографий. Для генерации псевдометок выравнивания мы устанавливаем координату спутникового изображения в качестве начала
координат,
а затем вычисляем углы между каждым видом дрона и
видом спутника. Оцененные углы затем используются для разделения
изображений на b ячеек каждые x градусов. Мы также извлекаем только
углы для их регрессии, но это может быть шумным,
потому что иерархическая локализация является только оценкой. Во время обучения вложения спутникового и
вида дрона используются для
предсказания псевдометок. Во время вывода эти веса больше не нужны.
Чтобы помочь модели изучить выравнивание, мы заменяем
случайное вращение на дополнение данных. В 30 % случаев
спутниковое изображение поворачивается, а псевдометка, указывающая ориентацию на спутниковое изображение, корректируется соответствующим образом как выровненное дополнение данных вращения.
### 3.2 Архитектура сети и функция потерь

Наша общая архитектура для обучения метрике адаптирована
из **==Deuser et al.==** Поэтому мы используем сиамскую
сеть с предварительно обученным кодировщиком изображений с разделением веса, как показано на рисунке 2. В наших экспериментах мы сравниваем **Vision Transformer** с современной **ConvNet**, поскольку Deuser et al. показали преимущества
**CNN** в геолокации с наземными видами. В качестве функции контрастных потерь для сопоставления перекрестных видов мы используем
потери **InfoNCE**. Эта функция потерь сопоставляет каждый
положительный образец со всеми другими отрицательными образцами в
пакете. Наличие двух или более изображений одного и того же здания с дрона в пакете ведет себя как шум метки для функции потерь.
Чтобы предотвратить такое поведение, мы выбираем только одно изображение здания с дрона в пакет. **В дополнение к ранее описанному**
**выровненному вращению мы используем цветовой джиттер, грубое выпадение, гауссово размытие и резкость изображений для дополнения данных.** Во время фазы обучения мы включаем легкий
линейный слой для **==прогнозирования сгенерированных меток ориентации на основе**
**конкатенированных выходных характеристик ветвей спутникового и БПЛА==**. Легкий линейный слой не используется для вывода, поэтому наш метод не требует никакой дополнительной вычислительной мощности по сравнению с Deuser et al. Мы используем
о**птимизатор AdamWas и используем косинусный**
**планировщик скорости обучения с разминкой**.
- В качестве пропорции разминки мы устанавливаем 10% шагов обучения и устанавливаем пиковую максимальную скорость обучения на 4e-5. 
- Сглаживание меток 0,1 используется в потере InfoNCE и в потере кросс-энтропии для дискретного предсказания ориентации. 
- В наших экспериментах мы также пытались регрессировать ориентацию, поэтому мы используем среднеквадратичную ошибку (MSE) в качестве функции потерь. 
- Контрастность и потеря ориентации взвешиваются в соотношении 2 к 1. 
- Мы обучаем наш подход в течение одной эпохи на учебном наборе University-1652 с 8 Nvidia V100 32Gb.


