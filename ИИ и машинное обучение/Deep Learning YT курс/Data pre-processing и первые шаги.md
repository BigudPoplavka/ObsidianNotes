#Машинное_обучение 

[[Стохастический градиентный спуск]]

![[Pasted image 20240819082557.png]]

**Препроцессинг** - подготовка данных для корректного старта и удобства тренировки модели.
## Смещение в центр-ноль

Находим среднее всех картинок и вычитаем из всех элементов среднее.
## Масштабировать оси к одному размеру

используется в случае, если разброс значений по переменным довольно разные.

`x` и `sigma` - многомерные вектора
## Инициализация весов

### Случайная инициализация

`W = a * randon(w, h)`

Важно правильновыбрать а, т.к. с каждым слоем при передаче `а` будет приходить след. степень `а`. Это важно во избежание взрыва и затухания градиента.
#### Выбор a - оно должно быть пропорционально корню из числа нейронов в слое

- ## ==Xavier init==
- ![[Pasted image 20240819084419.png]]
- `torch.nn.init.xavier_normal_`

Но так как у нас ReLU после каждого слоя, то для сохранения их общего поведения и примерно общего уровня активации. Оптимизация лучше т.к. мы не убиваем половину ReLU

![[Pasted image 20240819084616.png]]
- `torch.nn.init.kaiming_normal_`
