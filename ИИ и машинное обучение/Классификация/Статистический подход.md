#Машинное_обучение 
[[Классификация]]

В статистическом подходе, в отличие от **детерминистских, для которых характерно однозначное отнесение образа к одному из классов**, полагается, что *объект может принадлежать любому из классов, но с некоторой вероятностью*. 

Сами же образы рассматриваются как отсчеты некоторого случайного вектора, 
принимающего значения из множества Χ и характеризующегося 
плотностью распределения вероятностей *p(х).*

Статистический подход также позволяет определять вероятность ошибочной 
классификации, с помощью которой и оценивается качество классификации.

#  Наивный байесовский алгоритм (НБА)

**Наивный байесовский алгоритм (НБА)** – это алгоритм 
классификации, основанный на теореме Байеса с допущением о 
независимости признаков. Другими словами, НБА предполагает, 
что наличие какого-либо признака в классе не связано с наличием 
какого-либо другого признака. 

Например, фрукт может считаться 
яблоком, если он красный, круглый и его диаметр составляет 
порядка 8 сантиметров. Даже если эти признаки зависят друг от 
друга или от других признаков, в любом случае они вносят 
независимый вклад в вероятность того, что этот фрукт является 
яблоком. В связи с таким допущением алгоритм называется 
«наивным».

Теорема Байеса позволяет рассчитать апостериорную 
вероятность **P(c|x)** на основе **P(c)**, **P(x)** и **P(x|c)**.

![[Pasted image 20230528001356.png]]

- **P(c|x)** – апостериорная вероятность данного класса c (т.е. 
вероятность того, что наблюдаемый образ x принадлежит классу с).
- **P(c)** – это априорная вероятность получения образа, 
принадлежащего данному классу.
- **P(x|c)** – плотность распределения вероятностей образов класса 
с или правдоподобие того, что из класса с будет выбран образ x.
- **P(x)** – априорная вероятность данного значения признака.

## Компоненты НБА

В классе классификатора будут такие поля:

сглаживание
набор классов
список априорных вероятностей каждого класса
список условных вероятностей признаков каждого класса 

        self.alpha = alpha    
        self.classes = None
        self.prior_probs = None
        self.cond_probs = None

- `fit(X, y)`: метод обучения классификатора на матрице признаков X и векторе меток классов y.
- `predict(X)`: метод прогнозирования меток классов для новых данных X.

- Аргумент `alpha` в методе инициализации является гиперпараметром модели и контролирует сглаживание вероятностей.

- Метод `fit(X, y)` оценивает априорные вероятности каждого класса и условные вероятности каждого признака для каждого класса. Это делается с помощью формул Байеса и мультиномиального распределения.

- Метод `predict(X)` прогнозирует метки классов для новых данных. Для каждого объекта входных данных он вычисляет логарифмическую сумму апостериорных вероятностей для всех классов. Классификатор выбирает класс с наибольшим значением этой суммы вероятностей.

## Принцип работы НБА

В наивном Байесовском классификаторе вероятности оцениваются с помощью **формулы Байеса и мультиномиального распределения.**

Допустим, у нас есть матрица признаков **X** и вектор меток классов **y**. Мы хотим оценить вероятность того, что новый объект **x** будет принадлежать к классу **c_i**, где **i** - номер класса и **c_i** - метка класса.

### Шаг 1

Первым шагом мы вычисляем априорную вероятность **P(c_i)**, которая оценивается как количество объектов класса **c_i**, деленное на общее количество объектов в выборке. Также мы можем добавить сглаживание, чтобы избежать нулевых вероятностей:

```
prior_prob = (np.sum(y == c_i) + alpha) / (len(y) + num_classes*alpha)
```

### Шаг 2

Затем мы оцениваем условную вероятность **P(x_j|c_i)** для каждого признака **x_j** для класса **c_i**. В наивном Байесовском классификаторе мы предполагаем, что каждый признак независимы друг от друга.

Почему именно условную? Условная вероятность  - это вероятность наступления события **А** при условии наступления события **В**. То есть: вероятность нахождения объекта класса cls при условии и нахождения признака x_i.

Берем признак X целевого класса cls и считаем вероятность, как отношение числа i-го признака у объекта с классом cls / общее число признаков этого класса.

```
cond_prob = (np.sum(X[y == c_i, j]) + alpha) / (np.sum(X[y == c_i]) + num_features*alpha)
```

Здесь `j` - это индекс признака `x_j`, `num_features` - это количество признаков/столбцов в матрице признаков `X`, `alpha` - это параметр сглаживания, и `X[y == c_i, j]` - это подматрица матрицы признаков `X`, соответствующая объектам класса c_i и признаку `x_j`.

### Шаг 3

Мы вычисляем логарифм от апостериорной вероятности для каждого класса и выбираем класс с наибольшим значением этой вероятности.

Необходимо найти произведение априорной вероятности классов на условную вероятность признаков. 

Мы используем логарифм, потому что перемножение вероятностей, указанных в формуле Байеса может привести к нижней границе точности численных значений, которые компьютер может хранить. Это проблема, известная как проблема недооценки точности или "underflow".

Логарифмическое преобразование может помочь избежать проблемы "underflow", поскольку при перемножении двух вероятностей (что было бы необходимо для вычисления апостериорной вероятности) мы можем использовать свойства логарифмов:

`log(ab) = log(a) + log(b)`

При использовании логарифма мы можем заменить перемножение вероятностей на их суммы логарифмов. Это позволяет избежать проблемы "underflow" и улучшить точность вычислений.

```
log_prior_prob = np.log(prior_prob) 
log_cond_prob = np.sum(np.log(cond_prob) * x_j) 
log_post_prob = log_prior_prob + log_cond_prob
```

Первая строка `log_prior_prob = np.log(prior_prob)` вычисляет **логарифм априорной вероятности класса** (например, вероятность P(c_i) в формуле Байеса), где `prior_prob` - это априорная вероятность класса `c_i`.

Вторая строка `log_cond_prob = np.sum(np.log(cond_prob) * x_j)` вычисляет логарифм условной вероятности признаков (например, вероятность P(x_j|c_i)), где `cond_prob` - это условная вероятность признаков x_j для класса c_i, вычисленная с помощью мультиномиального распределения. `x_j` - **это значение признака j для нового объекта, которое мы сравниваем с обученной моделью.**

Третья строка `log_post_prob = log_prior_prob + log_cond_prob` **вычисляет логарифм апостериорной вероятности класса** (например, вероятность P(c_i|x)), используя логарифм априорной вероятности `log_prior_prob` и логарифм условной вероятности `log_cond_prob`.

Затем мы используем апостериорные вероятности для классификации нового объекта, **выбирая класс с максимальной апостериорной вероятностью.**